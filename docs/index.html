<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="imitation learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Penalty-Based Imitation Learning With Cross Semantics Generation Sensor Fusion for Autonomous Driving</title>
  <link rel="icon" type="image/x-icon" href="static/images/capybara.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Penalty-Based Imitation Learning With Cross Semantics Generation Sensor Fusion for Autonomous Driving</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://hongkuan-zhou.github.io/Homepage/" target="_blank">Hongkuan Zhou</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Aifen Sui</a><sup>* &#8224;</sup>,
              </span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Letian Shi</a><sup>*</sup>,
              </span>
              <span class="author-block">
                <a href="Fourth AUTHOR PERSONAL LINK" target="_blank">Yinxian Li</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Huawei Munich Research Center, Technical University of Munich<br>IEEE International Conference on Intelligent Transportation Systems ITSC 2023</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution  <sup>&#8224;</sup>Corresponding Author</small></span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2303.11888" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                        </a>
                      </span>

                    <!-- Supplementary PDF link -->
<!--                      <span class="link-block">-->
<!--                        <a href="static/pdfs/supplementary_material.pdf" target="_blank"-->
<!--                        class="external-link button is-normal is-rounded is-dark">-->
<!--                        <span class="icon">-->
<!--                          <i class="fas fa-file-pdf"></i>-->
<!--                        </span>-->
<!--                        <span>Supplementary</span>-->
<!--                        </a>-->
<!--                      </span>-->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2303.11888" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!--<section class="hero teaser">-->
<!--  <div class="container is-max-desktop">-->
<!--    <div class="hero-body">-->
<!--      <video poster="" id="tree" autoplay controls muted loop height="100%">-->
<!--        &lt;!&ndash; Your video here &ndash;&gt;-->
<!--        <source src="static/videos/banner_video.mp4"-->
<!--        type="video/mp4">-->
<!--      </video>-->
<!--      <h2 class="subtitle has-text-centered">-->
<!--        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. -->
<!--      </h2>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent times, there has been a growing focus on end-to-end autonomous driving technologies. This technology involves the replacement of the entire driving pipeline with a single neural network, which has a simpler structure and faster inference time. However, while this approach reduces the number of components in the driving pipeline, it also presents challenges related to interpretability and safety. For instance, the trained policy may not always comply with traffic rules, and it is difficult to determine the reason for such misbehavior due to the lack of intermediate outputs. Additionally, the successful implementation of autonomous driving technology heavily depends on the reliable and expedient processing of sensory data to accurately perceive the surrounding environment. In this paper, we provide penalty-based imitation learning approach combined with cross semantics generation sensor fusion technologies (PCSG) to efficiently integrate multiple modalities of information and enable the autonomous agent to effectively adhere to traffic regulations. Our model undergoes evaluation within the Town 05 Long benchmark, where we observe a remarkable increase in the driving score by more than 12% when compared to the state-of-the-art (SOTA) model, InterFuser. Notably, our model achieves this performance enhancement while achieving a 7- fold increase in inference speed and reducing the model size by approximately 30%.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop content">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/architecture.png" alt="MY ALT TEXT"/> <br>
          <div class="content has-text-justified">
            <p>
              The top-down LiDAR pseudo image and front camera image go through two residual networks to extract 512 dimension feature vectors. We use four different MLPs to extract the shared features and the unique features. The unique features of RGB input are used to generate stop signs and traffic light indicators. The shared features of LiDAR are used to reconstruct the segmentation of RGB input while the shared features of RGB are used to reconstruct the segmentation of top-down LiDAR input. An alignment loss is used to align the shared features from LiDAR and camera inputs into the same space. These shared features and unique features are concatenated along with the measurements (velocity, throttle, steer, brake from the last frame) and then go through one MLP to reduce the size. Finally, they will be fed into one GRU decoder to predict short-term waypoints.
            </p>
          </div>
        </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/penalty.png" alt="MY ALT TEXT"/>
        <div class="content has-text-justified">
          <p>
            To ensure compliance with red light and stop penalty rules, as well as promoting deceleration during turning maneuvers, our approach incorporates three distinct penalty types. The first column of the figures exemplifies the red light penalty, wherein waypoints situated beyond the stop line receive a penalty when the traffic light is red. In the second column, we demonstrate the stop sign penalty, wherein predicted waypoints within the vicinity of a stop sign are penalized if the agent fails to decelerate adequately. The speed penalty is enforced during turning actions as shown in last two figures. Specifically, if the predicted waypoints indicate an excessive speed, a speed penalty is imposed.
          </p>
        </div>
     </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <h2 class="title is-3">Video Presentation</h2>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--        <div class="column is-four-fifths">-->
<!--          -->
<!--          <div class="publication-video">-->
<!--            &lt;!&ndash; Youtube embed code here &ndash;&gt;-->
<!--            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End youtube video -->


<!-- Video carousel -->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title is-3">Another Carousel</h2>-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-video1">-->
<!--          <video poster="" id="video1" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel1.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video2">-->
<!--          <video poster="" id="video2" autoplay controls muted loop height="100%">-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel2.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-video3">-->
<!--          <video poster="" id="video3" autoplay controls muted loop height="100%">\-->
<!--            &lt;!&ndash; Your video file here &ndash;&gt;-->
<!--            <source src="static/videos/carousel3.mp4"-->
<!--            type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->
<!-- End video carousel -->






<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->

  <!-- Experiments -->
  <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title">Experiments</h2>
        <table class="table is-bordered is-striped is-fullwidth">
          <thead>
            <tr>
              <th>Model</th>
              <th>Driving Score</th>
              <th>Route Complication</th>
              <th>Infraction Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th>LateFusion</th>
              <td>32.34</td>
              <td>60.41</td>
              <td>0.61</td>
            </tr>
            <tr>
              <th>Geometric Fusion</th>
              <td>31.30</td>
              <td>57.17</td>
              <td>0.54</td>
            </tr>
            <tr>
              <th>InterFuser</th>
              <td>50.64</td>
              <td>89.13</td>
              <td>0.57</td>
            </tr>
            <tr>
              <th>Transfuser+</th>
              <td>36.19</td>
              <td>70.13</td>
              <td>0.51</td>
            </tr>
            <tr>
              <th>Transfuser</th>
              <td>34.50</td>
              <td>61.16</td>
              <td>0.56</td>
            </tr>
            <tr>
              <th>P_CSG</th>
              <td><strong>56.38</strong></td>
              <td><strong>94.00</strong></td>
              <td><strong>0.61</strong></td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </section>
<!--Experiments -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @misc{zhou2023penaltybased,
              title={Penalty-Based Imitation Learning With Cross Semantics
              Generation Sensor Fusion for Autonomous Driving},
              author={Hongkuan Zhou and Aifen Sui and Letian Shi and Yinxian Li},
              year={2023},
              eprint={2303.11888},
              archivePrefix={arXiv},
              primaryClass={cs.RO}
        }
      </code></pre>
    </div>
  </section>
<!--End BibTex citation -->

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container is-max-desktop content">
        <div class="columns is-vcentered">
          <div class="column">
            <div class="column is-centered has-text-centered">
              <span class="icon">
                <i class="fa fa-map-marker"></i>
              </span>
              <div class="content">
                <h4>Address</h4>
                <p>Riesstraße 25, 80992 München</p>
              </div>
            </div>

          </div>
          <div class="column">
            <div class="column is-centered has-text-centered">
              <span class="icon">
                <i class="fas fa-envelope"></i>
              </span>
              <div class="content">
                <h4>Contact</h4>
                <a href="mailto:aifen.sui@huawei.com">aifen.sui@huawei.com</a>
              </div>
            </div>
          </div>
        </div>
        <div>
    </div>
  </section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This work is supported by Trustworthy Technology and Engineering, Huawei Munich Research Center.
          </p>

        </div>
      </div>
    </div>
  </div>
  </footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
